# Activity solutions {#sec-solutions}

::: {.callout-note}
## Suggested `R` code solutions

This section will be update with my suggested solutions to the class wide activities after their conclusion. I **strongly** recommend that you review these outside of class if only to familiarise yourself with a different approach.
:::


## Suggested solution to @sec-gorilla

```{r, eval = FALSE}
require(tidyverse)
## read in data
data <- readr::read_csv("https://raw.githubusercontent.com/STATS-UOA/databunker/master/data/BMI.csv")
data
## Mean BMI
data %>%
    summarise(mean(bmi)) %>%
    round()
## Max BMI males
data %>%
    filter(gender == "male") %>%
    filter(bmi == max(bmi))
## t-test BMI males vs females
t.test(bmi ~ gender, data = data)
## t-test steps males vs females
t.test(steps ~ gender, data = data) 

## plotting. ALWAYS PLOT YOUR DATA!
ggplot(data, aes(x = steps, y = bmi, col = gender)) +
    geom_point()
```

## Suggested solution to @sec-honesty

```{r, eval = FALSE}
library(tidyverse)
data <- read_csv("https://raw.githubusercontent.com/STATS-UOA/databunker/master/data/retracted-honesty-study_week-02.csv")
## set up descriptive treatments
data <- data %>% mutate (treatment = ifelse(Cond==0, "No signature",
                                     ifelse(Cond==1, "Sign-Top",
                                     ifelse(Cond==2, "Sign-Bottom" , NA))))
## remove control condition (here we're only interested in comparing sign-top and sign-bottom)
data_sub <- data %>% filter(., Cond != 0)
## MATCH PAPER
## "lowered the share of people over-reporting their math puzzle performance from 79% to 37%"
## with "chi sq test p(0.0013)"
prop.table(table(data_sub$CheatedOnMatrixTax, data_sub$treatment), margin = 2)
table(data_sub$CheatedOnMatrixTax, data_sub$treatment) |> chisq.test()
## "lowered the average amount of over-reporting from 3.94 puzzles to 0.77 puzzles (p < .00001)"
t.test(OverReport ~ treatment, data = data_sub)
## "nearly halved the average amount of claimed commuting expenses, from $9.62 to $5.27 (p = .0014)"
t.test(SumDeduction ~ treatment, data = data_sub)

## DATA DETECTIVING
## lm
mod <- lm(SumDeduction ~ treatment, data = data_sub)
mod |> summary() ## matches t-test above (is the same thing)
## plot makes sense
ggplot(data_sub, aes(x = treatment, y = SumDeduction)) +
    geom_violin() + geom_jitter()
## mapping flagged observations to colour
ggplot(data_sub, aes(x = treatment, y = SumDeduction)) +
    geom_violin() + geom_jitter(aes(col = as.factor(flag)))
## residuals
data_sub$residuals <- residuals(mod)
ggplot(data_sub, aes(x = treatment, y = residuals)) +
    geom_point(aes(col = as.factor(flag))) +
    geom_hline(yintercept = 0, col = "grey", linewidth = 2, linetype = 2)
## now removing flagged observations
## lm
data_sub %>%
    filter(., flag == 0) %>%
    t.test(SumDeduction ~ treatment, data = .)

## see https://datacolada.org/109
## and/or https://www.theguardian.com/education/2023/jun/25/harvard-professor-data-fraud
## for the story


```

## Suggested solution to @sec-draw

```{r, eval = FALSE}
## data source: https://docs.google.com/spreadsheets/d/1YSJ4ypkYLq6j1mIBJCgUHhHjJZQ0Rkfe1qW2WC5HLiw/edit#gid=748627588
library(tidyverse)
data <- read_csv("https://raw.githubusercontent.com/STATS-UOA/databunker/master/data/marvel_movies.csv") %>%
	mutate(critics_score = as.numeric(str_replace_all(`critics % score`, "%", ""))) %>%
	mutate(budget_recovered = as.numeric(str_replace_all(`% budget recovered`, "%", "")))
##### ##### ##### ###
##### Model 1 #######
##### ##### ##### ###
data %>%
	lm(budget_recovered ~ critics_score, data = .) |>
	summary()
## Ans
data %>%
	ggplot(., aes(y = budget_recovered, x = critics_score)) +
	geom_smooth(method = "lm", se = FALSE) + ylab(" Estimated budget_recovered")
## w. data
data %>%
	ggplot(., aes(y = budget_recovered, x = critics_score)) +
	geom_smooth(method = "lm", se = FALSE) + geom_point()
##### ##### ##### ###
##### Model 2 #######
##### ##### ##### ###
names(table(data$category))
mod <- data %>%
	lm(budget_recovered ~  category, data = .) 
mod |>
	summary()
## Ans
data$pred_vals <- predict(mod)
## plot
data %>%
	ggplot(aes(y = pred_vals, x = category)) +
    geom_point(size = 15, pch = "-") + ylab(" Estimated budget_recovered")

##### ##### ##### ###
##### Model 3 #######
##### ##### ##### ###
mod <- data %>%
	lm(budget_recovered ~ critics_score + category, data = .) 
mod |>
	summary()
## Ans
data$pred_vals <- predict(mod)
## plot
data %>%
	ggplot(aes(y = pred_vals, x = critics_score, color = category)) +
	geom_line() + ylab(" Estimated budget_recovered")

##### ##### ##### ###
##### Model 4 #######
##### ##### ##### ###
mod <- data %>%
	lm(budget_recovered ~ critics_score*category, data = .) 
mod |>
	summary()
## Ans
data$pred_vals <- predict(mod)
## plot
data %>%
	ggplot(aes(y = pred_vals, x = critics_score, color = category)) +
	geom_line() + ylab(" Estimated budget_recovered")

##### ##### ##### ###
##### Model 5 #######
##### ##### ##### ###
data <- data %>%
	rename(., "worldwide" = `worldwide gross ($m)`, "domestic" = `domestic gross ($m)`,
				 "international" = `international gross ($m)`)
mod <- lm(worldwide ~ 0 + domestic + international, data = data) 
mod |> summary()
## Ans
## plot
require(rsm) ## install if not available
persp(mod, form =  ~ 0 + domestic + international)
image(mod, form =  ~ 0 + domestic + international)
##### ##### ##### ###
##### Model 6 #######
##### ##### ##### ###
mod <- lm(worldwide ~ budget*critics_score, data = data) 
mod |>	summary()
## Ans
## plot
persp(mod, form =  ~ budget*critics_score)
image(mod, form =  ~ budget*critics_score)


```

## Suggested solution to @sec-fry

```{r, eval = FALSE}
## paper https://www.sciencedirect.com/science/article/pii/S1658077X17302655?via%3Dihub#t0005
## Figure 1 data 'extracted' by https://automeris.io/WebPlotDigitizer/

library(tidyverse)
fries <- read_csv("https://raw.githubusercontent.com/STATS-UOA/databunker/master/data/fries.csv")

ggplot(fries, aes(x = frying_time_s, y = frying_temp_c, col = method)) +
    geom_line() + geom_point() + geom_smooth(method = "lm", se = FALSE)

ggplot(fries, aes(x = frying_time_s, y = frying_temp_c, col = method)) +
    geom_line() + geom_point() + stat_smooth(method = "lm",formula = y~poly(x, 2, raw=TRUE), se = FALSE)

ggplot(fries, aes(x = frying_time_s, y = frying_temp_c, col = method)) +
    geom_line() + geom_point() + stat_smooth(method = "lm",formula = y~poly(x, 3, raw=TRUE), se = FALSE)

## first degree
lm(frying_temp_c ~ frying_time_s + method, data = fries) |>
    gglm::gglm()
ggplot(fries, aes(x = frying_time_s, y = frying_temp_c, col = method)) +
    geom_line() + geom_point() + geom_smooth(method = "lm", se = FALSE)
## second degree
lm(frying_temp_c ~ I(frying_time_s^2) + method, data = fries) |>
gglm::gglm()
ggplot(fries, aes(x = frying_time_s, y = frying_temp_c, col = method)) +
    geom_line() + geom_point() + stat_smooth(method = "lm",formula = y~poly(x, 2, raw=TRUE), se = FALSE)
## third degree
mod <- lm(frying_temp_c ~ I(frying_time_s^1) +  I(frying_time_s^2) +  I(frying_time_s^3) + method,
          data = fries, na.action = "na.fail")
mod |> summary()
mod |>
   gglm::gglm()
mod <- lm(frying_temp_c ~ poly(frying_time_s, 3, raw = TRUE) + method, data = fries) ## but these are correlated
mod |>
summary()
ggplot(fries, aes(x = frying_time_s, y = frying_temp_c, col = method)) +
    geom_line() + geom_point() + stat_smooth(method = "lm",formula = y~poly(x, 3, raw=TRUE), se = FALSE)
mod |>  gglm::gglm()
## orthogonal model
mod <- lm(frying_temp_c ~ poly(frying_time_s, 3) + method, data = fries, na.action = "na.fail") ## see https://stackoverflow.com/questions/29999900/poly-in-lm-difference-between-raw-vs-orthogonal
mod |>
summary()
mod |>  gglm::gglm()
## remove the 180 obvs as these are not 'data' they are determined
data <- fries %>%
    filter(frying_temp_c != 180)
data %>%
    ggplot(., aes(x = sqrt(frying_time_s), y = frying_temp_c, col = method)) +
    geom_line(alpha = 0.5) + geom_point() 
mod <- lm(frying_temp_c ~ poly(log(frying_time_s), 3) + method, data = data) 
mod |>
summary()
mod |>  gglm::gglm()
data %>%
    mutate(preds = predict(mod)) %>%
    ggplot(., aes(x = sqrt(frying_time_s), y = frying_temp_c, col = method)) +
    geom_line(alpha = 0.1) + geom_point() +  geom_line(aes(y = preds))

## Model diagnostics not looking "great" still. But how can we choose the "best" possible?
## We could manually compare pairs of models using ANOVA/AIC etc. or...
require(MuMIn) ## remembering which letters are capatalised is a pain
## stands for Multi Model Inference
mod <- lm(frying_temp_c ~ poly(log(frying_time_s), 3) + method, data = data, na.action = na.fail)
## na.action = na.fail is so MuMIn dredge works
MuMIn::dredge(mod)


```

## Code example to support @sec-mods / @sec-ss

```{r, eval = FALSE}
base_url <- "https://raw.githubusercontent.com/STATS-UOA/databunker/master/data/"
factorial <- read.csv(paste(base_url, "factorial_expt.csv", sep = ""))
factorial$Disease <- as.factor(factorial$Disease)
factorial$Organ <- as.factor(factorial$Organ)
unbalanced <- factorial[- c(1:3,10), ]
## Null model.
fit.null <- lm(logAUC ~ 1, data = unbalanced)
summary(fit.null)
## Only Factor Disease.
fit.a <- lm(logAUC ~ Disease, data = unbalanced)
summary(fit.a)
## Factors Disease and Organ.
fit.ab <- lm(logAUC ~ Disease + Organ, data = unbalanced)
summary(fit.ab)
## Factors Disease and Organ with interaction.
fit.abi <- lm(logAUC ~ Disease*Organ, data = unbalanced)
## ANOVA table
anova(fit.abi)
## First line.
sum(residuals(fit.null)^2) - sum(residuals(fit.a)^2)
## Second line.
sum(residuals(fit.a)^2) - sum(residuals(fit.ab)^2)
## Third line.
sum(residuals(fit.ab)^2) - sum(residuals(fit.abi)^2)
## Final line.
sum(residuals(fit.abi)^2)
## Type II sums of squares
car::Anova(fit.abi, type = 2)
```


## Suggested solution to @sec-ss

```{r, eval = FALSE}
## using "gorilla" data from lecture 01
## example only
require(tidyverse)
data <- read_csv("https://raw.githubusercontent.com/STATS-UOA/databunker/master/data/BMI.csv")
data %>% 
   mutate(grand_mean = mean(bmi)) %>%
   mutate(sstotal = (bmi - grand_mean) ^2 ) %>%
   group_by(gender) %>%
   mutate(treatment_mean = mean(bmi),
          sse = (bmi - treatment_mean)^2,
          tmp = (treatment_mean - grand_mean)^2) %>%
   summarise(ss_tot = sum(sstotal), ss_e = sum(sse), ss_treat = sum(tmp)) %>%
   pull(ss_treat) %>% sum()
## compare to SS value in
aov(bmi ~ gender, data = data)
```

